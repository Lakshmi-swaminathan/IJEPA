{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgRkGxEpmvxS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import alexnet\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "8F3V-2vDnDJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-defined AlexNet model and modify for CIFAR-10\n",
        "model = alexnet(pretrained=False)  # Set pretrained=True for transfer learning\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)  # Adjust final layer for 10 classes\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "0vQUlViWnVCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train(model, trainloader, testloader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(tqdm(trainloader)):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Log training loss\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        # Evaluate on the test set after each epoch\n",
        "        test_loss, test_accuracy = evaluate(model, testloader)\n",
        "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Evaluation function for validation loop\n",
        "def evaluate(model, testloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    total_loss /= len(testloader)\n",
        "    accuracy = 100.0 * correct / len(testloader.dataset)\n",
        "    return total_loss, accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "HvEhPiOznZqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for specified number of epochs\n",
        "epochs = 10\n",
        "train(model, trainloader, testloader, epochs)\n",
        "\n",
        "# Save model checkpoint\n",
        "torch.save(model.state_dict(), 'alexnet_cifar10.pth')\n",
        "print(\"Model checkpoint saved.\")\n"
      ],
      "metadata": {
        "id": "-4M8gDG0ncrA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}