{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d806a9-2cf2-4d2d-bd38-1d048c2d3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "def posemb_sincos_2d(h, w, dim, temperature: int = 10000, dtype = torch.float32):\n",
    "    y, x = torch.meshgrid(torch.arange(h), torch.arange(w), indexing=\"ij\")\n",
    "    assert (dim % 4) == 0, \"feature dimension must be multiple of 4 for sincos emb\"\n",
    "    omega = torch.arange(dim // 4) / (dim // 4 - 1)\n",
    "    omega = 1.0 / (temperature ** omega)\n",
    "\n",
    "    y = y.flatten()[:, None] * omega[None, :]\n",
    "    x = x.flatten()[:, None] * omega[None, :]\n",
    "    pe = torch.cat((x.sin(), x.cos(), y.sin(), y.cos()), dim=1)\n",
    "    return pe.type(dtype)\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),  # Normalization is done along the last dimension by default\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head),\n",
    "                FeedForward(dim, mlp_dim)\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return self.norm(x)\n",
    "\n",
    "class SimpleViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels = 3, dim_head = 64):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange(\"b c (h p1) (w p2) -> b (h w) (p1 p2 c)\", p1 = patch_height, p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = posemb_sincos_2d(\n",
    "            h = image_height // patch_height,\n",
    "            w = image_width // patch_width,\n",
    "            dim = dim,\n",
    "        )\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim)\n",
    "\n",
    "        self.pool = \"mean\"\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.linear_head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        device = img.device\n",
    "\n",
    "        x = self.to_patch_embedding(img)\n",
    "        x += self.pos_embedding.to(device, dtype=x.dtype)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim = 1)\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.linear_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820a3eb5-dd14-461d-a039-42d644f2c8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: einops in ./.local/lib/python3.9/site-packages (0.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install einops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de659d20-3bee-4253-94e5-3de4f41e14e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|██████████| 782/782 [03:46<00:00,  3.46it/s, Loss=2.0733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.34%\n",
      "New best model saved with accuracy: 26.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 782/782 [03:48<00:00,  3.43it/s, Loss=1.9098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 30.55%\n",
      "New best model saved with accuracy: 30.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 782/782 [03:44<00:00,  3.49it/s, Loss=1.9778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 782/782 [03:46<00:00,  3.45it/s, Loss=1.9915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 782/782 [03:45<00:00,  3.47it/s, Loss=1.9897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|██████████| 782/782 [03:44<00:00,  3.49it/s, Loss=1.9606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|██████████| 782/782 [03:45<00:00,  3.47it/s, Loss=2.0181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 22.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|██████████| 782/782 [03:47<00:00,  3.44it/s, Loss=1.9972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|██████████| 782/782 [03:45<00:00,  3.46it/s, Loss=1.9870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 782/782 [03:45<00:00,  3.46it/s, Loss=1.9722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.86%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # For progress bar\n",
    "import os\n",
    "\n",
    "# 1. Prepare CIFAR-10 Dataset (Full Dataset)\n",
    "def get_cifar10_dataloader(batch_size=128):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize to match Vision Transformer input size\n",
    "        transforms.ToTensor(),         # Convert to tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# 2. Define the Vision Transformer Model\n",
    "def create_vit_model():\n",
    "    return SimpleViT(\n",
    "        image_size=256,   # Input image size\n",
    "        patch_size=32,    # Patch size for splitting the image\n",
    "        num_classes=10,   # CIFAR-10 has 10 classes\n",
    "        dim=1024,         # Embedding dimension\n",
    "        depth=6,          # Number of transformer layers\n",
    "        heads=16,         # Number of attention heads\n",
    "        mlp_dim=2048      # Feed-forward hidden layer size\n",
    "    )\n",
    "\n",
    "# 3. Define the Training Function with Progress Bar\n",
    "def train_model(model, train_loader, test_loader, device, epochs=10, lr=0.001, save_path=\"./best_model.pth\"):\n",
    "    criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Optimizer\n",
    "    best_accuracy = 0.0  # Track the best accuracy\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Use tqdm for a progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{running_loss / len(train_loader):.4f}\"})\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = evaluate_model(model, test_loader, device)\n",
    "\n",
    "        # Save the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"New best model saved with accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "# 4. Define the Evaluation Function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            preds = model(images)\n",
    "            _, predicted = torch.max(preds, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# 5. Main Function\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    lr = 0.001\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    save_path = \"./best_model.pth\"\n",
    "\n",
    "    # Prepare data\n",
    "    train_loader, test_loader = get_cifar10_dataloader(batch_size)\n",
    "\n",
    "    # Create model\n",
    "    model = create_vit_model()\n",
    "\n",
    "    # Check if a saved model exists and load it\n",
    "    if os.path.exists(save_path):\n",
    "        print(\"Loading existing model...\")\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Train model\n",
    "    train_model(model, train_loader, test_loader, device, epochs, lr, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d93e16-02b5-4ab4-b328-0c45c04cd02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193781/1959310182.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model...\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]: 100%|██████████| 782/782 [03:45<00:00,  3.46it/s, Loss=1.9967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.01%\n",
      "New best model saved with accuracy: 25.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]: 100%|██████████| 782/782 [03:44<00:00,  3.48it/s, Loss=2.0481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]: 100%|██████████| 782/782 [03:44<00:00,  3.48it/s, Loss=2.0663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]: 100%|██████████| 782/782 [03:45<00:00,  3.46it/s, Loss=2.0432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 22.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]: 100%|██████████| 782/782 [03:46<00:00,  3.45it/s, Loss=2.0088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]: 100%|██████████| 782/782 [03:44<00:00,  3.48it/s, Loss=2.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]: 100%|██████████| 782/782 [03:43<00:00,  3.49it/s, Loss=2.0017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.11%\n",
      "New best model saved with accuracy: 26.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]: 100%|██████████| 782/782 [03:44<00:00,  3.48it/s, Loss=1.9576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 27.62%\n",
      "New best model saved with accuracy: 27.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]: 100%|██████████| 782/782 [03:44<00:00,  3.48it/s, Loss=1.9309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 27.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]: 100%|██████████| 782/782 [03:45<00:00,  3.47it/s, Loss=1.9181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.43%\n",
      "New best model saved with accuracy: 29.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]: 100%|██████████| 782/782 [03:44<00:00,  3.49it/s, Loss=1.9334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]: 100%|██████████| 782/782 [03:43<00:00,  3.50it/s, Loss=1.9222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]: 100%|██████████| 782/782 [03:45<00:00,  3.47it/s, Loss=1.9068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.77%\n",
      "New best model saved with accuracy: 29.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]: 100%|██████████| 782/782 [03:43<00:00,  3.50it/s, Loss=1.9143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]:  52%|█████▏    | 409/782 [01:57<01:51,  3.35it/s, Loss=0.9943]"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Define the Training Function with Progress Bar\n",
    "def train_model(model, train_loader, test_loader, device, epochs=10, lr=0.001, save_path=\"./best_model.pth\"):\n",
    "    criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Optimizer\n",
    "    best_accuracy = 0.0  # Track the best accuracy\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Use tqdm for a progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{running_loss / len(train_loader):.4f}\"})\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = evaluate_model(model, test_loader, device)\n",
    "\n",
    "        # Save the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"New best model saved with accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "# 4. Define the Evaluation Function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            preds = model(images)\n",
    "            _, predicted = torch.max(preds, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# 5. Main Function\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    batch_size = 64\n",
    "    epochs = 20\n",
    "    lr = 0.001\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    save_path = \"./best_model.pth\"\n",
    "\n",
    "    # Prepare data\n",
    "    train_loader, test_loader = get_cifar10_dataloader(batch_size)\n",
    "\n",
    "    # Create model\n",
    "    model = create_vit_model()\n",
    "\n",
    "    # Check if a saved model exists and load it\n",
    "    if os.path.exists(save_path):\n",
    "        print(\"Loading existing model...\")\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Train model\n",
    "    train_model(model, train_loader, test_loader, device, epochs, lr, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8324e-4c73-4888-9c28-3d24fb2eba95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
